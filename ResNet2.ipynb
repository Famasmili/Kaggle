{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "264d1453-4aa6-47e5-89c4-eeb840ca00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e35f51f-6f17-4f9b-9c6c-4f80c2595f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_original_array(preds):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        index_column = np.arange(1, preds.size + 1)\n",
    "\n",
    "        # Reshape index_column and labels_train_modified to 2D column vectors\n",
    "        index_column = index_column.reshape(-1, 1)\n",
    "        labels_column = preds.reshape(-1, 1)\n",
    "\n",
    "        # Concatenate the index column with the labels column\n",
    "        combined_array = np.hstack((index_column, labels_column))\n",
    "\n",
    "        return combined_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de3f688-97a9-42be-94d8-7c8b3aec46d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 05:19:12,019 - INFO - Training data shape: (97477, 28, 28)\n",
      "2024-12-02 05:19:12,019 - INFO - Test data shape: (1000, 28, 28)\n",
      "2024-12-02 05:19:12,020 - INFO - Label distribution: [33484 10213  7754 46026]\n",
      "2024-12-02 05:19:12,098 - INFO - Using device: cuda\n",
      "2024-12-02 05:19:12,111 - INFO - Training Fold 1/5\n",
      "2024-12-02 05:19:20,785 - INFO - Fold 1, Epoch 1/7\n",
      "2024-12-02 05:19:20,786 - INFO - Train Loss: 0.4847, Train Acc: 82.98%\n",
      "2024-12-02 05:19:20,786 - INFO - Val Loss: 0.4052, Val Acc: 85.80%\n",
      "2024-12-02 05:19:20,786 - INFO - AUC per class: ['0.9847', '0.9658', '0.8578', '0.9682']\n",
      "2024-12-02 05:19:28,599 - INFO - Fold 1, Epoch 2/7\n",
      "2024-12-02 05:19:28,600 - INFO - Train Loss: 0.3556, Train Acc: 87.52%\n",
      "2024-12-02 05:19:28,600 - INFO - Val Loss: 0.3415, Val Acc: 88.48%\n",
      "2024-12-02 05:19:28,601 - INFO - AUC per class: ['0.9894', '0.9726', '0.8865', '0.9748']\n",
      "2024-12-02 05:19:36,411 - INFO - Fold 1, Epoch 3/7\n",
      "2024-12-02 05:19:36,412 - INFO - Train Loss: 0.3131, Train Acc: 88.97%\n",
      "2024-12-02 05:19:36,412 - INFO - Val Loss: 0.3118, Val Acc: 89.34%\n",
      "2024-12-02 05:19:36,413 - INFO - AUC per class: ['0.9902', '0.9794', '0.9026', '0.9775']\n",
      "2024-12-02 05:19:44,094 - INFO - Fold 1, Epoch 4/7\n",
      "2024-12-02 05:19:44,095 - INFO - Train Loss: 0.2871, Train Acc: 89.89%\n",
      "2024-12-02 05:19:44,096 - INFO - Val Loss: 0.3018, Val Acc: 89.59%\n",
      "2024-12-02 05:19:44,096 - INFO - AUC per class: ['0.9912', '0.9802', '0.9065', '0.9797']\n",
      "2024-12-02 05:19:51,896 - INFO - Fold 1, Epoch 5/7\n",
      "2024-12-02 05:19:51,897 - INFO - Train Loss: 0.2628, Train Acc: 90.71%\n",
      "2024-12-02 05:19:51,898 - INFO - Val Loss: 0.3341, Val Acc: 88.21%\n",
      "2024-12-02 05:19:51,898 - INFO - AUC per class: ['0.9907', '0.9734', '0.9025', '0.9807']\n",
      "2024-12-02 05:19:59,733 - INFO - Fold 1, Epoch 6/7\n",
      "2024-12-02 05:19:59,734 - INFO - Train Loss: 0.2406, Train Acc: 91.45%\n",
      "2024-12-02 05:19:59,735 - INFO - Val Loss: 0.3023, Val Acc: 89.47%\n",
      "2024-12-02 05:19:59,735 - INFO - AUC per class: ['0.9918', '0.9828', '0.9066', '0.9803']\n",
      "2024-12-02 05:20:07,525 - INFO - Fold 1, Epoch 7/7\n",
      "2024-12-02 05:20:07,526 - INFO - Train Loss: 0.2172, Train Acc: 92.41%\n",
      "2024-12-02 05:20:07,527 - INFO - Val Loss: 0.2820, Val Acc: 90.53%\n",
      "2024-12-02 05:20:07,527 - INFO - AUC per class: ['0.9932', '0.9833', '0.9113', '0.9812']\n",
      "2024-12-02 05:20:07,555 - INFO - Training Fold 2/5\n",
      "2024-12-02 05:20:15,370 - INFO - Fold 2, Epoch 1/7\n",
      "2024-12-02 05:20:15,371 - INFO - Train Loss: 0.4906, Train Acc: 82.83%\n",
      "2024-12-02 05:20:15,371 - INFO - Val Loss: 0.4155, Val Acc: 85.87%\n",
      "2024-12-02 05:20:15,372 - INFO - AUC per class: ['0.9848', '0.9629', '0.8559', '0.9674']\n",
      "2024-12-02 05:20:23,208 - INFO - Fold 2, Epoch 2/7\n",
      "2024-12-02 05:20:23,209 - INFO - Train Loss: 0.3546, Train Acc: 87.55%\n",
      "2024-12-02 05:20:23,209 - INFO - Val Loss: 0.3378, Val Acc: 88.33%\n",
      "2024-12-02 05:20:23,210 - INFO - AUC per class: ['0.9890', '0.9792', '0.8929', '0.9752']\n",
      "2024-12-02 05:20:31,059 - INFO - Fold 2, Epoch 3/7\n",
      "2024-12-02 05:20:31,059 - INFO - Train Loss: 0.3123, Train Acc: 89.20%\n",
      "2024-12-02 05:20:31,060 - INFO - Val Loss: 0.3988, Val Acc: 85.76%\n",
      "2024-12-02 05:20:31,061 - INFO - AUC per class: ['0.9904', '0.9655', '0.8976', '0.9746']\n",
      "2024-12-02 05:20:38,880 - INFO - Fold 2, Epoch 4/7\n",
      "2024-12-02 05:20:38,881 - INFO - Train Loss: 0.2871, Train Acc: 89.93%\n",
      "2024-12-02 05:20:38,881 - INFO - Val Loss: 0.3537, Val Acc: 87.81%\n",
      "2024-12-02 05:20:38,882 - INFO - AUC per class: ['0.9885', '0.9815', '0.8900', '0.9772']\n",
      "2024-12-02 05:20:46,731 - INFO - Fold 2, Epoch 5/7\n",
      "2024-12-02 05:20:46,732 - INFO - Train Loss: 0.2636, Train Acc: 90.74%\n",
      "2024-12-02 05:20:46,732 - INFO - Val Loss: 0.3493, Val Acc: 88.67%\n",
      "2024-12-02 05:20:46,732 - INFO - AUC per class: ['0.9914', '0.9816', '0.8983', '0.9791']\n",
      "2024-12-02 05:20:54,596 - INFO - Fold 2, Epoch 6/7\n",
      "2024-12-02 05:20:54,596 - INFO - Train Loss: 0.2418, Train Acc: 91.48%\n",
      "2024-12-02 05:20:54,597 - INFO - Val Loss: 0.2993, Val Acc: 89.74%\n",
      "2024-12-02 05:20:54,598 - INFO - AUC per class: ['0.9915', '0.9816', '0.9086', '0.9794']\n",
      "2024-12-02 05:21:02,479 - INFO - Fold 2, Epoch 7/7\n",
      "2024-12-02 05:21:02,480 - INFO - Train Loss: 0.2197, Train Acc: 92.24%\n",
      "2024-12-02 05:21:02,480 - INFO - Val Loss: 0.2869, Val Acc: 89.91%\n",
      "2024-12-02 05:21:02,481 - INFO - AUC per class: ['0.9926', '0.9843', '0.9164', '0.9806']\n",
      "2024-12-02 05:21:02,508 - INFO - Training Fold 3/5\n",
      "2024-12-02 05:21:10,464 - INFO - Fold 3, Epoch 1/7\n",
      "2024-12-02 05:21:10,465 - INFO - Train Loss: 0.4917, Train Acc: 82.90%\n",
      "2024-12-02 05:21:10,465 - INFO - Val Loss: 0.4461, Val Acc: 83.98%\n",
      "2024-12-02 05:21:10,466 - INFO - AUC per class: ['0.9837', '0.9612', '0.8569', '0.9683']\n",
      "2024-12-02 05:21:18,318 - INFO - Fold 3, Epoch 2/7\n",
      "2024-12-02 05:21:18,319 - INFO - Train Loss: 0.3613, Train Acc: 87.34%\n",
      "2024-12-02 05:21:18,319 - INFO - Val Loss: 0.3350, Val Acc: 87.93%\n",
      "2024-12-02 05:21:18,320 - INFO - AUC per class: ['0.9898', '0.9793', '0.8859', '0.9770']\n",
      "2024-12-02 05:21:26,167 - INFO - Fold 3, Epoch 3/7\n",
      "2024-12-02 05:21:26,168 - INFO - Train Loss: 0.3183, Train Acc: 88.98%\n",
      "2024-12-02 05:21:26,169 - INFO - Val Loss: 0.3297, Val Acc: 88.54%\n",
      "2024-12-02 05:21:26,170 - INFO - AUC per class: ['0.9909', '0.9767', '0.8972', '0.9784']\n",
      "2024-12-02 05:21:33,997 - INFO - Fold 3, Epoch 4/7\n",
      "2024-12-02 05:21:33,997 - INFO - Train Loss: 0.2912, Train Acc: 89.85%\n",
      "2024-12-02 05:21:33,998 - INFO - Val Loss: 0.2895, Val Acc: 89.93%\n",
      "2024-12-02 05:21:33,998 - INFO - AUC per class: ['0.9915', '0.9833', '0.9089', '0.9803']\n",
      "2024-12-02 05:21:41,844 - INFO - Fold 3, Epoch 5/7\n",
      "2024-12-02 05:21:41,845 - INFO - Train Loss: 0.2682, Train Acc: 90.72%\n",
      "2024-12-02 05:21:41,845 - INFO - Val Loss: 0.3171, Val Acc: 89.14%\n",
      "2024-12-02 05:21:41,846 - INFO - AUC per class: ['0.9901', '0.9806', '0.9047', '0.9806']\n",
      "2024-12-02 05:21:49,726 - INFO - Fold 3, Epoch 6/7\n",
      "2024-12-02 05:21:49,727 - INFO - Train Loss: 0.2450, Train Acc: 91.38%\n",
      "2024-12-02 05:21:49,727 - INFO - Val Loss: 0.3259, Val Acc: 89.10%\n",
      "2024-12-02 05:21:49,728 - INFO - AUC per class: ['0.9920', '0.9819', '0.8917', '0.9787']\n",
      "2024-12-02 05:21:57,529 - INFO - Fold 3, Epoch 7/7\n",
      "2024-12-02 05:21:57,529 - INFO - Train Loss: 0.2232, Train Acc: 92.14%\n",
      "2024-12-02 05:21:57,530 - INFO - Val Loss: 0.2862, Val Acc: 90.19%\n",
      "2024-12-02 05:21:57,531 - INFO - AUC per class: ['0.9921', '0.9847', '0.9095', '0.9811']\n",
      "2024-12-02 05:21:57,557 - INFO - Training Fold 4/5\n",
      "2024-12-02 05:22:05,440 - INFO - Fold 4, Epoch 1/7\n",
      "2024-12-02 05:22:05,440 - INFO - Train Loss: 0.4771, Train Acc: 83.19%\n",
      "2024-12-02 05:22:05,441 - INFO - Val Loss: 0.3511, Val Acc: 87.90%\n",
      "2024-12-02 05:22:05,442 - INFO - AUC per class: ['0.9881', '0.9715', '0.8819', '0.9737']\n",
      "2024-12-02 05:22:13,263 - INFO - Fold 4, Epoch 2/7\n",
      "2024-12-02 05:22:13,264 - INFO - Train Loss: 0.3508, Train Acc: 87.63%\n",
      "2024-12-02 05:22:13,265 - INFO - Val Loss: 0.3488, Val Acc: 88.16%\n",
      "2024-12-02 05:22:13,265 - INFO - AUC per class: ['0.9902', '0.9779', '0.8810', '0.9762']\n",
      "2024-12-02 05:22:21,196 - INFO - Fold 4, Epoch 3/7\n",
      "2024-12-02 05:22:21,196 - INFO - Train Loss: 0.3113, Train Acc: 89.13%\n",
      "2024-12-02 05:22:21,197 - INFO - Val Loss: 0.3324, Val Acc: 88.32%\n",
      "2024-12-02 05:22:21,197 - INFO - AUC per class: ['0.9916', '0.9765', '0.8873', '0.9785']\n",
      "2024-12-02 05:22:29,052 - INFO - Fold 4, Epoch 4/7\n",
      "2024-12-02 05:22:29,053 - INFO - Train Loss: 0.2873, Train Acc: 89.88%\n",
      "2024-12-02 05:22:29,054 - INFO - Val Loss: 0.3212, Val Acc: 88.79%\n",
      "2024-12-02 05:22:29,054 - INFO - AUC per class: ['0.9917', '0.9804', '0.9005', '0.9785']\n",
      "2024-12-02 05:22:36,927 - INFO - Fold 4, Epoch 5/7\n",
      "2024-12-02 05:22:36,928 - INFO - Train Loss: 0.2665, Train Acc: 90.61%\n",
      "2024-12-02 05:22:36,929 - INFO - Val Loss: 0.3281, Val Acc: 88.98%\n",
      "2024-12-02 05:22:36,929 - INFO - AUC per class: ['0.9919', '0.9808', '0.8897', '0.9791']\n",
      "2024-12-02 05:22:44,865 - INFO - Fold 4, Epoch 6/7\n",
      "2024-12-02 05:22:44,866 - INFO - Train Loss: 0.2423, Train Acc: 91.42%\n",
      "2024-12-02 05:22:44,866 - INFO - Val Loss: 0.3298, Val Acc: 89.08%\n",
      "2024-12-02 05:22:44,867 - INFO - AUC per class: ['0.9919', '0.9830', '0.8921', '0.9796']\n",
      "2024-12-02 05:22:52,842 - INFO - Fold 4, Epoch 7/7\n",
      "2024-12-02 05:22:52,843 - INFO - Train Loss: 0.2226, Train Acc: 92.23%\n",
      "2024-12-02 05:22:52,844 - INFO - Val Loss: 0.2996, Val Acc: 89.86%\n",
      "2024-12-02 05:22:52,844 - INFO - AUC per class: ['0.9917', '0.9834', '0.9099', '0.9803']\n",
      "2024-12-02 05:22:52,872 - INFO - Training Fold 5/5\n",
      "2024-12-02 05:23:00,813 - INFO - Fold 5, Epoch 1/7\n",
      "2024-12-02 05:23:00,814 - INFO - Train Loss: 0.4864, Train Acc: 83.04%\n",
      "2024-12-02 05:23:00,815 - INFO - Val Loss: 0.3938, Val Acc: 86.35%\n",
      "2024-12-02 05:23:00,815 - INFO - AUC per class: ['0.9857', '0.9693', '0.8562', '0.9705']\n",
      "2024-12-02 05:23:08,668 - INFO - Fold 5, Epoch 2/7\n",
      "2024-12-02 05:23:08,669 - INFO - Train Loss: 0.3577, Train Acc: 87.50%\n",
      "2024-12-02 05:23:08,669 - INFO - Val Loss: 0.3933, Val Acc: 85.91%\n",
      "2024-12-02 05:23:08,670 - INFO - AUC per class: ['0.9886', '0.9765', '0.8699', '0.9744']\n",
      "2024-12-02 05:23:16,470 - INFO - Fold 5, Epoch 3/7\n",
      "2024-12-02 05:23:16,472 - INFO - Train Loss: 0.3153, Train Acc: 88.95%\n",
      "2024-12-02 05:23:16,472 - INFO - Val Loss: 0.3280, Val Acc: 88.40%\n",
      "2024-12-02 05:23:16,473 - INFO - AUC per class: ['0.9906', '0.9771', '0.8944', '0.9764']\n",
      "2024-12-02 05:23:24,335 - INFO - Fold 5, Epoch 4/7\n",
      "2024-12-02 05:23:24,336 - INFO - Train Loss: 0.2888, Train Acc: 89.94%\n",
      "2024-12-02 05:23:24,336 - INFO - Val Loss: 0.3050, Val Acc: 89.43%\n",
      "2024-12-02 05:23:24,337 - INFO - AUC per class: ['0.9914', '0.9818', '0.9110', '0.9795']\n",
      "2024-12-02 05:23:32,284 - INFO - Fold 5, Epoch 5/7\n",
      "2024-12-02 05:23:32,285 - INFO - Train Loss: 0.2660, Train Acc: 90.71%\n",
      "2024-12-02 05:23:32,286 - INFO - Val Loss: 0.3068, Val Acc: 89.40%\n",
      "2024-12-02 05:23:32,286 - INFO - AUC per class: ['0.9916', '0.9821', '0.9011', '0.9787']\n",
      "2024-12-02 05:23:40,074 - INFO - Fold 5, Epoch 6/7\n",
      "2024-12-02 05:23:40,075 - INFO - Train Loss: 0.2434, Train Acc: 91.45%\n",
      "2024-12-02 05:23:40,075 - INFO - Val Loss: 0.3127, Val Acc: 89.05%\n",
      "2024-12-02 05:23:40,076 - INFO - AUC per class: ['0.9917', '0.9835', '0.9011', '0.9797']\n",
      "2024-12-02 05:23:47,865 - INFO - Fold 5, Epoch 7/7\n",
      "2024-12-02 05:23:47,866 - INFO - Train Loss: 0.2193, Train Acc: 92.24%\n",
      "2024-12-02 05:23:47,866 - INFO - Val Loss: 0.2944, Val Acc: 90.03%\n",
      "2024-12-02 05:23:47,867 - INFO - AUC per class: ['0.9920', '0.9840', '0.9110', '0.9795']\n"
     ]
    }
   ],
   "source": [
    "# Python script to run the custom Resnet model and save all important information\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('training.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create directories for saving results\n",
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "Path(\"plots\").mkdir(exist_ok=True)\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load the pickle files containing the dataset.\"\"\"\n",
    "    # Load training data\n",
    "    with open('train_data.pkl', 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "    \n",
    "    # Load test data\n",
    "    with open('test_data.pkl', 'rb') as f:\n",
    "        test_data = pickle.load(f)\n",
    "    \n",
    "    X_train = np.array(train_data['images'])\n",
    "    y_train = np.array(train_data['labels'])\n",
    "    X_test = np.array(test_data['images'])\n",
    "    \n",
    "    logging.info(f\"Training data shape: {X_train.shape}\")\n",
    "    logging.info(f\"Test data shape: {X_test.shape}\")\n",
    "    logging.info(f\"Label distribution: {np.bincount(y_train)}\")\n",
    "    \n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "class RetinalDataset(Dataset):\n",
    "    def __init__(self, images, labels=None, transform=None):\n",
    "        self.images = torch.FloatTensor(images).unsqueeze(1)  # Add channel dimension\n",
    "        self.labels = torch.LongTensor(labels) if labels is not None else None\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            return image, self.labels[idx]\n",
    "        return image\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                              stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                              stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                         stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.layer1 = self.make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self.make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(256, 2, stride=2)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def make_layer(self, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(ResBlock(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, device, config):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        self.optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=config['learning_rate'],\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accs = []\n",
    "        self.val_accs = []\n",
    "    \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, target)\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "            \n",
    "        return total_loss / len(train_loader), 100. * correct / total\n",
    "\n",
    "    def validate(self, val_loader):\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                val_loss += self.criterion(output, target).item()\n",
    "                \n",
    "                _, predicted = output.max(1)\n",
    "                total += target.size(0)\n",
    "                correct += predicted.eq(target).sum().item()\n",
    "                \n",
    "                all_preds.extend(F.softmax(output, dim=1).cpu().numpy())\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        accuracy = 100. * correct / total\n",
    "        \n",
    "        # Calculate AUC for each class\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_targets = np.array(all_targets)\n",
    "        aucs = []\n",
    "        for i in range(4):\n",
    "            y_true = (all_targets == i).astype(int)\n",
    "            y_pred = all_preds[:, i]\n",
    "            try:\n",
    "                auc = roc_auc_score(y_true, y_pred)\n",
    "                aucs.append(auc)\n",
    "            except:\n",
    "                aucs.append(0.0)\n",
    "        \n",
    "        return val_loss, accuracy, aucs\n",
    "\n",
    "        \n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'seed': 42,\n",
    "        'batch_size': 64,\n",
    "        'learning_rate': 2e-4,\n",
    "        'n_epochs': 7,\n",
    "        'n_folds': 5\n",
    "    }\n",
    "    \n",
    "    # Set random seeds\n",
    "    torch.manual_seed(config['seed'])\n",
    "    np.random.seed(config['seed'])\n",
    "    \n",
    "    # Load data\n",
    "    X_train, y_train, X_test = load_data()\n",
    "    \n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize K-fold cross validation\n",
    "    skf = StratifiedKFold(n_splits=config['n_folds'], shuffle=True, random_state=config['seed'])\n",
    "    \n",
    "    # Transform for training\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "    ])\n",
    "    \n",
    "    # Store fold results\n",
    "    fold_results = []\n",
    "    \n",
    "    # K-fold Cross Validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        logging.info(f\"Training Fold {fold + 1}/{config['n_folds']}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx]\n",
    "        y_val_fold = y_train[val_idx]\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = RetinalDataset(X_train_fold, y_train_fold)\n",
    "        val_dataset = RetinalDataset(X_val_fold, y_val_fold)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=config['batch_size'])\n",
    "        \n",
    "        # Initialize model and trainer\n",
    "        model = CustomResNet()\n",
    "        trainer = Trainer(model, device, config)\n",
    "        \n",
    "        # Training loop\n",
    "        best_val_acc = 0\n",
    "        for epoch in range(config['n_epochs']):\n",
    "            train_loss, train_acc = trainer.train_epoch(train_loader)\n",
    "            val_loss, val_acc, aucs = trainer.validate(val_loader)\n",
    "            \n",
    "            \n",
    "            logging.info(f\"Fold {fold + 1}, Epoch {epoch + 1}/{config['n_epochs']}\")\n",
    "            logging.info(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "            logging.info(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "            logging.info(f\"AUC per class: {[f'{auc:.4f}' for auc in aucs]}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save(model.state_dict(), f\"models/best_model_fold_{fold + 1}.pth\")\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold + 1,\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'final_aucs': aucs\n",
    "        })\n",
    "    \n",
    "    # Save fold results\n",
    "    with open('results/fold_results.json', 'w') as f:\n",
    "        json.dump(fold_results, f, indent=4)\n",
    "    \n",
    "    # Generate predictions for test set\n",
    "    test_dataset = RetinalDataset(X_test, transform=None)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'])\n",
    "    \n",
    "    # Ensemble predictions from all folds\n",
    "    all_predictions = []\n",
    "    for fold in range(config['n_folds']):\n",
    "        model = CustomResNet()\n",
    "        model.load_state_dict(torch.load(f\"models/best_model_fold_{fold + 1}.pth\"))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        fold_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                data = data.to(device)\n",
    "                output = model(data)\n",
    "                probabilities = F.softmax(output, dim=1)\n",
    "                fold_predictions.extend(probabilities.cpu().numpy())\n",
    "        \n",
    "        all_predictions.append(fold_predictions)\n",
    "    \n",
    "    # Average predictions from all folds\n",
    "    final_predictions = np.mean(all_predictions, axis=0)\n",
    "    predicted_labels = np.argmax(final_predictions, axis=1)\n",
    "    \n",
    "    # Save predictions\n",
    "    pd.DataFrame({\n",
    "        'id': range(1, len(predicted_labels) + 1),\n",
    "        'label': predicted_labels\n",
    "    }).to_csv('results/test_predictions.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "832fc292-57a3-4704-9d43-9c28ca394958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Predictions: 1000\n",
      "Different Predictions: 221\n",
      "Percentage Difference: 22.10%\n"
     ]
    }
   ],
   "source": [
    "cnn_aug = pd.read_csv('CNN_baseline_aug_attempt.csv')\n",
    "cnn_augboth = pd.read_csv('CNN_baseline_augboth_attempt.csv')\n",
    "\n",
    "df_resnet = pd.read_csv('./results/test_predictions.csv')\n",
    "#df_resnet['id'] += 1\n",
    "\n",
    "# Assuming the predicted classes are in a column named 'Class'\n",
    "differences = (df_resnet['label'] != cnn_augboth[' Class']).sum()\n",
    "total = len(df_resnet)\n",
    "\n",
    "print(f\"Total Predictions: {total}\")\n",
    "print(f\"Different Predictions: {differences}\")\n",
    "print(f\"Percentage Difference: {(differences / total) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1026c-1059-4c5b-8b30-a33805e9cc61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
