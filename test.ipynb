{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from solution import SVMEx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load t h e p i c k l e f i l e\n",
    "with open ( 'train_data.pkl' , 'rb' ) as f :\n",
    "    data = pickle.load ( f )\n",
    "# Access images and l a b e l s\n",
    "images = data ['images']\n",
    "labels = data ['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.array(images)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97477, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97477,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97477, 784)\n"
     ]
    }
   ],
   "source": [
    "flattened_images = images.reshape(images.shape[0], -1)\n",
    "print(flattened_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "num_samples = flattened_images.shape[0]\n",
    "\n",
    "indices = np.arange(num_samples)\n",
    "np.random.shuffle(indices)\n",
    "shuffled_images = flattened_images[indices]\n",
    "shuffled_labels = labels[indices]\n",
    "\n",
    "baseline1Idxs = int(num_samples * 0.8)  # 80% for training, 20% for validation\n",
    "split_index=int(baseline1Idxs*0.8)\n",
    "\n",
    "train_images = shuffled_images[:split_index]\n",
    "train_labels = shuffled_labels[:split_index]\n",
    "\n",
    "val_images = shuffled_images[split_index:]\n",
    "val_labels = shuffled_labels[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 10.0227, Val Loss = 10.0306, Train Acc = 0.5249, Val Acc = 0.5225\n",
      "Epoch 2: Train Loss = 9.7994, Val Loss = 9.8158, Train Acc = 0.5426, Val Acc = 0.5399\n",
      "Epoch 3: Train Loss = 9.6511, Val Loss = 9.6759, Train Acc = 0.5684, Val Acc = 0.5662\n",
      "Epoch 4: Train Loss = 9.5111, Val Loss = 9.5362, Train Acc = 0.5751, Val Acc = 0.5724\n",
      "Epoch 5: Train Loss = 9.4254, Val Loss = 9.4546, Train Acc = 0.5770, Val Acc = 0.5735\n",
      "Epoch 6: Train Loss = 9.3221, Val Loss = 9.3535, Train Acc = 0.5931, Val Acc = 0.5878\n",
      "Epoch 7: Train Loss = 9.2540, Val Loss = 9.2866, Train Acc = 0.5983, Val Acc = 0.5933\n",
      "Epoch 8: Train Loss = 9.1933, Val Loss = 9.2246, Train Acc = 0.6007, Val Acc = 0.5967\n",
      "Epoch 9: Train Loss = 9.1384, Val Loss = 9.1728, Train Acc = 0.6087, Val Acc = 0.6048\n",
      "Epoch 10: Train Loss = 9.0978, Val Loss = 9.1306, Train Acc = 0.6091, Val Acc = 0.6059\n",
      "Epoch 11: Train Loss = 9.0678, Val Loss = 9.1019, Train Acc = 0.6083, Val Acc = 0.6047\n",
      "Epoch 12: Train Loss = 9.0291, Val Loss = 9.0670, Train Acc = 0.6089, Val Acc = 0.6051\n",
      "Epoch 13: Train Loss = 9.0012, Val Loss = 9.0404, Train Acc = 0.6148, Val Acc = 0.6105\n",
      "Epoch 14: Train Loss = 8.9619, Val Loss = 8.9999, Train Acc = 0.6161, Val Acc = 0.6132\n",
      "Epoch 15: Train Loss = 8.9357, Val Loss = 8.9780, Train Acc = 0.6159, Val Acc = 0.6107\n",
      "Epoch 16: Train Loss = 8.9153, Val Loss = 8.9561, Train Acc = 0.6192, Val Acc = 0.6158\n",
      "Epoch 17: Train Loss = 8.9100, Val Loss = 8.9495, Train Acc = 0.6203, Val Acc = 0.6176\n",
      "Epoch 18: Train Loss = 8.8671, Val Loss = 8.9104, Train Acc = 0.6229, Val Acc = 0.6190\n",
      "Epoch 19: Train Loss = 8.8572, Val Loss = 8.9004, Train Acc = 0.6224, Val Acc = 0.6190\n",
      "Epoch 20: Train Loss = 8.8665, Val Loss = 8.9123, Train Acc = 0.6219, Val Acc = 0.6190\n",
      "Epoch 21: Train Loss = 8.8245, Val Loss = 8.8663, Train Acc = 0.6233, Val Acc = 0.6196\n",
      "Epoch 22: Train Loss = 8.8082, Val Loss = 8.8530, Train Acc = 0.6250, Val Acc = 0.6209\n",
      "Epoch 23: Train Loss = 8.7925, Val Loss = 8.8398, Train Acc = 0.6248, Val Acc = 0.6218\n",
      "Epoch 24: Train Loss = 8.7991, Val Loss = 8.8444, Train Acc = 0.6252, Val Acc = 0.6207\n",
      "Epoch 25: Train Loss = 8.7760, Val Loss = 8.8266, Train Acc = 0.6258, Val Acc = 0.6226\n",
      "Epoch 26: Train Loss = 8.7639, Val Loss = 8.8103, Train Acc = 0.6263, Val Acc = 0.6241\n",
      "Epoch 27: Train Loss = 8.7554, Val Loss = 8.8057, Train Acc = 0.6267, Val Acc = 0.6236\n",
      "Epoch 28: Train Loss = 8.7399, Val Loss = 8.7869, Train Acc = 0.6281, Val Acc = 0.6258\n",
      "Epoch 29: Train Loss = 8.7360, Val Loss = 8.7864, Train Acc = 0.6284, Val Acc = 0.6257\n",
      "Epoch 30: Train Loss = 8.7269, Val Loss = 8.7779, Train Acc = 0.6286, Val Acc = 0.6266\n",
      "Epoch 31: Train Loss = 8.7091, Val Loss = 8.7598, Train Acc = 0.6291, Val Acc = 0.6262\n",
      "Epoch 32: Train Loss = 8.7049, Val Loss = 8.7574, Train Acc = 0.6289, Val Acc = 0.6253\n",
      "Epoch 33: Train Loss = 8.7081, Val Loss = 8.7594, Train Acc = 0.6288, Val Acc = 0.6275\n",
      "Epoch 34: Train Loss = 8.6993, Val Loss = 8.7517, Train Acc = 0.6297, Val Acc = 0.6267\n",
      "Epoch 35: Train Loss = 8.6805, Val Loss = 8.7355, Train Acc = 0.6296, Val Acc = 0.6268\n",
      "Epoch 36: Train Loss = 8.6737, Val Loss = 8.7288, Train Acc = 0.6299, Val Acc = 0.6270\n",
      "Epoch 37: Train Loss = 8.6831, Val Loss = 8.7404, Train Acc = 0.6296, Val Acc = 0.6255\n",
      "Epoch 38: Train Loss = 8.6689, Val Loss = 8.7293, Train Acc = 0.6302, Val Acc = 0.6268\n",
      "Epoch 39: Train Loss = 8.6675, Val Loss = 8.7269, Train Acc = 0.6295, Val Acc = 0.6252\n",
      "Epoch 40: Train Loss = 8.6577, Val Loss = 8.7116, Train Acc = 0.6314, Val Acc = 0.6302\n",
      "Epoch 41: Train Loss = 8.6496, Val Loss = 8.7075, Train Acc = 0.6315, Val Acc = 0.6284\n",
      "Epoch 42: Train Loss = 8.6715, Val Loss = 8.7321, Train Acc = 0.6311, Val Acc = 0.6292\n",
      "Epoch 43: Train Loss = 8.6404, Val Loss = 8.6988, Train Acc = 0.6318, Val Acc = 0.6287\n",
      "Epoch 44: Train Loss = 8.6505, Val Loss = 8.7103, Train Acc = 0.6306, Val Acc = 0.6274\n",
      "Epoch 45: Train Loss = 8.6306, Val Loss = 8.6906, Train Acc = 0.6317, Val Acc = 0.6280\n",
      "Epoch 46: Train Loss = 8.6409, Val Loss = 8.7015, Train Acc = 0.6330, Val Acc = 0.6299\n",
      "Epoch 47: Train Loss = 8.6233, Val Loss = 8.6878, Train Acc = 0.6320, Val Acc = 0.6286\n",
      "Epoch 48: Train Loss = 8.6229, Val Loss = 8.6825, Train Acc = 0.6327, Val Acc = 0.6287\n",
      "Epoch 49: Train Loss = 8.6191, Val Loss = 8.6810, Train Acc = 0.6328, Val Acc = 0.6282\n",
      "Epoch 50: Train Loss = 8.6154, Val Loss = 8.6789, Train Acc = 0.6325, Val Acc = 0.6298\n",
      "Epoch 51: Train Loss = 8.6093, Val Loss = 8.6724, Train Acc = 0.6321, Val Acc = 0.6287\n",
      "Epoch 52: Train Loss = 8.6210, Val Loss = 8.6859, Train Acc = 0.6324, Val Acc = 0.6286\n",
      "Epoch 53: Train Loss = 8.5984, Val Loss = 8.6634, Train Acc = 0.6332, Val Acc = 0.6296\n",
      "Epoch 54: Train Loss = 8.6070, Val Loss = 8.6706, Train Acc = 0.6337, Val Acc = 0.6296\n",
      "Epoch 55: Train Loss = 8.5936, Val Loss = 8.6591, Train Acc = 0.6331, Val Acc = 0.6299\n",
      "Epoch 56: Train Loss = 8.5929, Val Loss = 8.6590, Train Acc = 0.6331, Val Acc = 0.6309\n",
      "Epoch 57: Train Loss = 8.6145, Val Loss = 8.6820, Train Acc = 0.6326, Val Acc = 0.6299\n",
      "Epoch 58: Train Loss = 8.5879, Val Loss = 8.6573, Train Acc = 0.6334, Val Acc = 0.6298\n",
      "Epoch 59: Train Loss = 8.5886, Val Loss = 8.6548, Train Acc = 0.6334, Val Acc = 0.6321\n",
      "Epoch 60: Train Loss = 8.5787, Val Loss = 8.6447, Train Acc = 0.6342, Val Acc = 0.6312\n",
      "Epoch 61: Train Loss = 8.5884, Val Loss = 8.6579, Train Acc = 0.6324, Val Acc = 0.6288\n",
      "Epoch 62: Train Loss = 8.6059, Val Loss = 8.6754, Train Acc = 0.6338, Val Acc = 0.6306\n",
      "Epoch 63: Train Loss = 8.5799, Val Loss = 8.6462, Train Acc = 0.6346, Val Acc = 0.6330\n",
      "Epoch 64: Train Loss = 8.5695, Val Loss = 8.6399, Train Acc = 0.6346, Val Acc = 0.6312\n",
      "Epoch 65: Train Loss = 8.5873, Val Loss = 8.6570, Train Acc = 0.6339, Val Acc = 0.6311\n",
      "Epoch 66: Train Loss = 8.5660, Val Loss = 8.6353, Train Acc = 0.6349, Val Acc = 0.6316\n",
      "Epoch 67: Train Loss = 8.5675, Val Loss = 8.6379, Train Acc = 0.6350, Val Acc = 0.6316\n",
      "Epoch 68: Train Loss = 8.5645, Val Loss = 8.6358, Train Acc = 0.6343, Val Acc = 0.6316\n",
      "Epoch 69: Train Loss = 8.6048, Val Loss = 8.6760, Train Acc = 0.6322, Val Acc = 0.6284\n",
      "Epoch 70: Train Loss = 8.5718, Val Loss = 8.6428, Train Acc = 0.6347, Val Acc = 0.6306\n",
      "Epoch 71: Train Loss = 8.5787, Val Loss = 8.6561, Train Acc = 0.6342, Val Acc = 0.6316\n",
      "Epoch 72: Train Loss = 8.5783, Val Loss = 8.6507, Train Acc = 0.6344, Val Acc = 0.6325\n",
      "Epoch 73: Train Loss = 8.5572, Val Loss = 8.6298, Train Acc = 0.6342, Val Acc = 0.6315\n",
      "Epoch 74: Train Loss = 8.5581, Val Loss = 8.6328, Train Acc = 0.6345, Val Acc = 0.6317\n",
      "Epoch 75: Train Loss = 8.5670, Val Loss = 8.6438, Train Acc = 0.6341, Val Acc = 0.6307\n",
      "Epoch 76: Train Loss = 8.5578, Val Loss = 8.6331, Train Acc = 0.6347, Val Acc = 0.6307\n",
      "Epoch 77: Train Loss = 8.5448, Val Loss = 8.6194, Train Acc = 0.6352, Val Acc = 0.6324\n",
      "Epoch 78: Train Loss = 8.5756, Val Loss = 8.6500, Train Acc = 0.6342, Val Acc = 0.6328\n",
      "Epoch 79: Train Loss = 8.5424, Val Loss = 8.6184, Train Acc = 0.6362, Val Acc = 0.6331\n",
      "Epoch 80: Train Loss = 8.5397, Val Loss = 8.6173, Train Acc = 0.6353, Val Acc = 0.6320\n",
      "Epoch 81: Train Loss = 8.5438, Val Loss = 8.6212, Train Acc = 0.6352, Val Acc = 0.6322\n",
      "Epoch 82: Train Loss = 8.5353, Val Loss = 8.6128, Train Acc = 0.6354, Val Acc = 0.6333\n",
      "Epoch 83: Train Loss = 8.5418, Val Loss = 8.6166, Train Acc = 0.6359, Val Acc = 0.6329\n",
      "Epoch 84: Train Loss = 8.5414, Val Loss = 8.6220, Train Acc = 0.6351, Val Acc = 0.6314\n",
      "Epoch 85: Train Loss = 8.5904, Val Loss = 8.6666, Train Acc = 0.6337, Val Acc = 0.6309\n",
      "Epoch 86: Train Loss = 8.5520, Val Loss = 8.6301, Train Acc = 0.6361, Val Acc = 0.6334\n",
      "Epoch 87: Train Loss = 8.5341, Val Loss = 8.6156, Train Acc = 0.6357, Val Acc = 0.6330\n",
      "Epoch 88: Train Loss = 8.5410, Val Loss = 8.6178, Train Acc = 0.6360, Val Acc = 0.6333\n",
      "Epoch 89: Train Loss = 8.5297, Val Loss = 8.6080, Train Acc = 0.6356, Val Acc = 0.6327\n",
      "Epoch 90: Train Loss = 8.5248, Val Loss = 8.6051, Train Acc = 0.6366, Val Acc = 0.6332\n",
      "Epoch 91: Train Loss = 8.5354, Val Loss = 8.6182, Train Acc = 0.6351, Val Acc = 0.6316\n",
      "Epoch 92: Train Loss = 8.5231, Val Loss = 8.6041, Train Acc = 0.6363, Val Acc = 0.6330\n",
      "Epoch 93: Train Loss = 8.5270, Val Loss = 8.6089, Train Acc = 0.6362, Val Acc = 0.6335\n",
      "Epoch 94: Train Loss = 8.5194, Val Loss = 8.6009, Train Acc = 0.6370, Val Acc = 0.6333\n",
      "Epoch 95: Train Loss = 8.5420, Val Loss = 8.6258, Train Acc = 0.6364, Val Acc = 0.6327\n",
      "Epoch 96: Train Loss = 8.5251, Val Loss = 8.6084, Train Acc = 0.6359, Val Acc = 0.6326\n",
      "Epoch 97: Train Loss = 8.5246, Val Loss = 8.6096, Train Acc = 0.6364, Val Acc = 0.6331\n",
      "Epoch 98: Train Loss = 8.5172, Val Loss = 8.5994, Train Acc = 0.6365, Val Acc = 0.6327\n",
      "Epoch 99: Train Loss = 8.5195, Val Loss = 8.6044, Train Acc = 0.6353, Val Acc = 0.6317\n",
      "Epoch 100: Train Loss = 8.5204, Val Loss = 8.6071, Train Acc = 0.6351, Val Acc = 0.6324\n"
     ]
    }
   ],
   "source": [
    "svm=SVMEx()\n",
    "weights_c1,history_c1=svm.fit(X_train=train_images, y_train=train_labels, \n",
    "                                X_val=val_images, y_val=val_labels,\n",
    "                        num_classes=4, epochs=100,\n",
    "                        learning_rate=0.001, C=0, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ( 'test_data.pkl' , 'rb' ) as f :\n",
    "    data = pickle.load ( f )\n",
    "# Access images and l a b e l s\n",
    "testimages = data ['images']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimages=np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_test_images = testimages.reshape(testimages.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds=svm.infer(flattened_test_images,weights_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_original_array(preds):\n",
    "        \"\"\"\n",
    "       \n",
    "        \"\"\"\n",
    "\n",
    "        index_column = np.arange(1, preds.size + 1)\n",
    "\n",
    "        # Reshape index_column and labels_train_modified to 2D column vectors\n",
    "        index_column = index_column.reshape(-1, 1)\n",
    "        labels_column = preds.reshape(-1, 1)\n",
    "\n",
    "        # Concatenate the index column with the labels column\n",
    "        combined_array = np.hstack((index_column, labels_column))\n",
    "\n",
    "        return combined_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=make_original_array(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions, columns=['ID', 'label'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('SVM_baseline1_attempt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest attempt\n",
    "Parameters: 100 estimators, random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(train_images, train_labels)\n",
    "\n",
    "# Predict on validation set\n",
    "val_preds = rf.predict(val_images)\n",
    "\n",
    "# Calculate accuracy\n",
    "val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "# Predict on test set\n",
    "test_preds_rf = rf.predict(flattened_test_images)\n",
    "\n",
    "# Convert predictions to original array format\n",
    "predictions_rf = make_original_array(test_preds_rf)\n",
    "\n",
    "# Create a DataFrame and save to CSV\n",
    "df_rf = pd.DataFrame(predictions_rf, columns=['ID', 'label'])\n",
    "df_rf.to_csv('RandomForest_baseline1_attempt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network attempt\n",
    "Preprocessing: Reshape images to 4D tensors, reshape labels to categorical variables\n",
    "CNN: 1st conv2d 32 channels, kernel size 3x3, relu, maxpooling 2x2, 2nd one 64 channels, kernel size 3x3, relu, maxpooling 2x2, flatten, to feed into 2 dense layers: 1st 128, relu, 2nd one 4, softmax for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Reshape images to 4D tensor for CNN input\n",
    "train_images_cnn = train_images.reshape(-1, 28, 28, 1)  # Assuming images are 28x28 pixels\n",
    "val_images_cnn = val_images.reshape(-1, 28, 28, 1)\n",
    "flattened_test_images_cnn = flattened_test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Convert labels to categorical\n",
    "train_labels_cnn = to_categorical(train_labels, num_classes=4)\n",
    "val_labels_cnn = to_categorical(val_labels, num_classes=4)\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "cnn_model.fit(train_images_cnn, train_labels_cnn, epochs=10, batch_size=32, validation_data=(val_images_cnn, val_labels_cnn))\n",
    "\n",
    "# Predict on test set\n",
    "test_preds_cnn = cnn_model.predict(flattened_test_images_cnn)\n",
    "test_preds_cnn_labels = np.argmax(test_preds_cnn, axis=1)\n",
    "\n",
    "# Convert predictions to original array format\n",
    "predictions_cnn = make_original_array(test_preds_cnn_labels)\n",
    "\n",
    "# Create a DataFrame and save to CSV\n",
    "df_cnn = pd.DataFrame(predictions_cnn, columns=['ID', 'label'])\n",
    "df_cnn.to_csv('CNN_baseline1_attempt.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Same model using Pytorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_images_tensor = torch.tensor(train_images_cnn, dtype=torch.float32).to(device)\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long).to(device)\n",
    "val_images_tensor = torch.tensor(val_images_cnn, dtype=torch.float32).to(device)\n",
    "val_labels_tensor = torch.tensor(val_labels, dtype=torch.long).to(device)\n",
    "test_images_tensor = torch.tensor(flattened_test_images_cnn, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "val_dataset = TensorDataset(val_images_tensor, val_labels_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, activation='relu')\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, activation='relu')\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "cnn_model = CNNModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validate the model\n",
    "    cnn_model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = cnn_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = val_correct / len(val_dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {val_loss}, Accuracy: {val_accuracy}')\n",
    "\n",
    "# Predict on test set\n",
    "cnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = cnn_model(test_images_tensor)\n",
    "    _, test_preds_cnn_labels = torch.max(test_outputs, 1)\n",
    "\n",
    "# Convert predictions to original array format\n",
    "predictions_cnn = make_original_array(test_preds_cnn_labels.numpy())\n",
    "\n",
    "# Create a DataFrame and save to CSV\n",
    "df_cnn = pd.DataFrame(predictions_cnn, columns=['ID', 'label'])\n",
    "df_cnn.to_csv('CNN_baseline1_attempt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This cell defines and compiles a ResNet50 model using TensorFlow and Keras.\n",
    "# The model is designed for image classification tasks and consists of the following components:\n",
    "# \n",
    "# 1. **Base Model**: \n",
    "#    - Architecture: ResNet50\n",
    "#    - Pre-trained Weights: ImageNet\n",
    "#    - Include Top: False (excluding the top fully connected layer)\n",
    "#    - Input Shape: (28, 28, 3) (assuming input images are 28x28 pixels with 3 color channels)\n",
    "# \n",
    "# 2. **Custom Layers**: \n",
    "#    - GlobalAveragePooling2D: Reduces each feature map to a single value.\n",
    "#    - Dense Layer: \n",
    "#      - Units: 128\n",
    "#      - Activation: ReLU\n",
    "#    - Dropout Layer: \n",
    "#      - Rate: 0.5 (to prevent overfitting)\n",
    "#    - Dense Layer: \n",
    "#      - Units: 4 (assuming 4 classes for classification)\n",
    "#      - Activation: Softmax\n",
    "# \n",
    "# The model is compiled with the following parameters:\n",
    "# - **Optimizer**: Adam\n",
    "# - **Loss Function**: Categorical Crossentropy (suitable for multi-class classification)\n",
    "# - **Metrics**: Accuracy (to monitor the accuracy during training and evaluation)\n",
    "# \n",
    "# Design Choices:\n",
    "# - The use of ResNet50 as the base model leverages pre-trained weights to improve feature extraction.\n",
    "# - GlobalAveragePooling2D is used to reduce the spatial dimensions of the feature maps.\n",
    "# - ReLU activation is chosen for its effectiveness in introducing non-linearity.\n",
    "# - Dropout is applied to prevent overfitting.\n",
    "# - The final Dense layer uses Softmax activation to output a probability distribution over the classes.\n",
    "# - Adam optimizer is selected for its efficiency and adaptive learning rate capabilities.\n",
    "# - Categorical Crossentropy is used as the loss function to handle one-hot encoded labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the ResNet50 model with pre-trained weights, excluding the top layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(28, 28, 3))\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert grayscale images to 3 channels by repeating the single channel 3 times\n",
    "train_images_resnet = np.repeat(train_images_cnn, 3, axis=-1)\n",
    "val_images_resnet = np.repeat(val_images_cnn, 3, axis=-1)\n",
    "flattened_test_images_resnet = np.repeat(flattened_test_images_cnn, 3, axis=-1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images_resnet, train_labels_cnn, epochs=10, batch_size=32, validation_data=(val_images_resnet, val_labels_cnn))\n",
    "\n",
    "# Predict on test set\n",
    "test_preds_resnet = model.predict(flattened_test_images_resnet)\n",
    "test_preds_resnet_labels = np.argmax(test_preds_resnet, axis=1)\n",
    "\n",
    "# Convert predictions to original array format\n",
    "predictions_resnet = make_original_array(test_preds_resnet_labels)\n",
    "\n",
    "# Create a DataFrame and save to CSV\n",
    "df_resnet = pd.DataFrame(predictions_resnet, columns=['ID', 'label'])\n",
    "df_resnet.to_csv('ResNet_baseline1_attempt.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50 attempt using PyTorch\n",
    "Parameters: 100 epochs, learning rate=0.001, batch size=32, dropout rate=0.5\n",
    "\n",
    "Preprocessing: Convert grayscale images to 3 channels by repeating the single channel 3 times\n",
    "\n",
    "Model Architecture:\n",
    "- Base Model: ResNet50 with pre-trained weights (ImageNet)\n",
    "- Custom Layers:\n",
    "    - Global Average Pooling\n",
    "    - Dense Layer: 128 units, ReLU activation\n",
    "    - Dropout Layer: 0.5 rate\n",
    "    - Dense Layer: 4 units, Softmax activation\n",
    "\n",
    "Training:\n",
    "- Loss Function: CrossEntropyLoss\n",
    "- Optimizer: Adam\n",
    "\n",
    "Evaluation:\n",
    "- Validation Accuracy and Loss per epoch\n",
    "- Predictions on test set saved to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load the ResNet50 model with pre-trained weights for retina medical images\n",
    "base_model = models.resnet50(weights='IMAGENET1K_V2').to(device)\n",
    "base_model.fc = nn.Identity()  # Remove the final fully connected layer\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(base_model.fc.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "model = CustomResNet(base_model).to(device)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Convert grayscale images to 3 channels by repeating the single channel 3 times\n",
    "train_images_resnet = np.repeat(train_images_cnn, 3, axis=1)\n",
    "val_images_resnet = np.repeat(val_images_cnn, 3, axis=1)\n",
    "flattened_test_images_resnet = np.repeat(flattened_test_images_cnn, 3, axis=1)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_images_tensor = torch.tensor(train_images_resnet, dtype=torch.float32).to(device)\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long).to(device)\n",
    "val_images_tensor = torch.tensor(val_images_resnet, dtype=torch.float32).to(device)\n",
    "val_labels_tensor = torch.tensor(val_labels, dtype=torch.long).to(device)\n",
    "test_images_tensor = torch.tensor(flattened_test_images_resnet, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "val_dataset = TensorDataset(val_images_tensor, val_labels_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = val_correct / len(val_dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {val_loss}, Accuracy: {val_accuracy}')\n",
    "\n",
    "# Predict on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_images_tensor)\n",
    "    _, test_preds_resnet_labels = torch.max(test_outputs, 1)\n",
    "\n",
    "# Convert predictions to original array format\n",
    "predictions_resnet = make_original_array(test_preds_resnet_labels.numpy())\n",
    "\n",
    "# Create a DataFrame and save to CSV\n",
    "df_resnet = pd.DataFrame(predictions_resnet, columns=['ID', 'label'])\n",
    "df_resnet.to_csv('ResNet_baseline1_attempt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
